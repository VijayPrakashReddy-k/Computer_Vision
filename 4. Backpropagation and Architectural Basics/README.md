## 4 - Backpropagation and Architectural Basics

*Architectural Basics: We go through 9 model iterations together, step-by-step to find the final architecture*

**Contents:**

- [BACK PROPAGATION](./README.md/#backpropagation)

- [FULLY CONNECTED LAYERS](./README.md/#FCL)

- [VGG - LAST AWESOME OLD ARCHITECTURE - PRE 2014](./README.md/#VGG)

- [MODERN ARCHITECTURE - POST 2014](./README.md/#resnet)

- [SOFTMAX](./README.md/#softmax)

- [ARCHITECTURAL BLOCKS](./README.md/#architecture)

      1. MAXPOOLING
      
      2. BATCH NORMALIZATION
      
      3. DROPOUT
      
      4. LEARNING RATE
      
      5. BATCH SIZE


<h1 align = 'center' id = "backpropagation"> BACKPROPAGATION</h1>

- `Neural networks come in many forms, but the main form we need to master is that of "fully connected layers".  A network with many such (or other) layers is called "deep".`

Let's look at a very simple neural network.
